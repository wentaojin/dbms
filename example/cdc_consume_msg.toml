task-name = "cdc-task00"
datasource-name-s = "ora151"
datasource-name-t = "tidb186"
comment = "测试数据源"

[case-field-rule]
# 控制配置文件内所有 *-s 参数配置值以及 column-route-rules 中的 key 值
# 1，参数值是 0 代表以当前配置文件为准，与源端对比
# 2，参数值是 1 代表统一转换值为小写，与源端对比
# 3，参数值是 2 代表统一转换值为大写，与源端对比
case-field-rule-s = "0"
# 控制配置文件 *-t 以及 column-route-rules 中的 value 值
# 1，参数值是 0 代表统一转换数据库名、表名、字段名值以当前配置文件为准
# 2，参数值是 1 代表统一转换数据库名、表名、字段名值为小写
# 3，参数值是 2 代表统一转换数据库名、表名、字段名值为大写
case-field-rule-t = "2"

[schema-route-rule]
schema-name-s = "SCOTT"
schema-name-t = "simple"
# include-table-s 迁移所有表需指定 "*"，特定表写具体表名
#include-table-s = ["MARVIN00","MARVIN01","MARVIN05","MARVIN_COLUMN_T"]
include-table-s = ["MARVIN01"]
#include-table-s = ["MARVIN00","MARVIN01","MARVIN05"]
#include-table-s = ["PM_TC_PROCESS_CODE","MARVIN00","MARVIN01"]
exclude-table-s = []

[[schema-route-rule.table-route-rules]]
table-name-s = ""
table-name-t = ""
column-route-rules = {}

[cdc-consume-param]
kafka-address = ["120.92.108.85:54323","120.92.108.85:54323","120.92.108.85:54323"]
subscribe-topic = "cdc_marvin_topic"
table-thread = 10
# 参考上游数据是否开启压缩，设置对应压缩算法
# 可选值有 "none"、"lz4"、"snappy"，默认为 "none"
message-compression = "none"
# ticdc 数据同步
# 避免由于 resolvedTs 前无数据而导致频繁刷新元数据，检查 <=resolvedTs 前是否有数据
# 如果有数据，则立即刷新，如果连续 X 个 resolvedT 没有数据，则达到 X 个 resolvedT 时再刷新
# ticdc 单个分区 ticdc 间隔生成 resolvedTs，约每 1 秒生成 1 个 resolvedTs，设置 300 代表约 5 min 刷新一次
idle-resolved-threshold = 300
# calltimeout，单位：秒
call-timeout = 36000
enable-checkpoint = true